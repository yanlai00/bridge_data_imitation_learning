{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import semiparametrictransfer\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0619 18:18:57.113574 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\n",
      "W0619 18:18:57.115878 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\n",
      "W0619 18:18:57.117273 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\n",
      "W0619 18:18:57.118747 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\n",
      "W0619 18:18:57.120066 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\n",
      "W0619 18:18:57.121470 140200702248704 warnings.py:99] /root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from semiparametrictransfer.data_sets.data_loader import FixLenVideoDataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from semiparametrictransfer.utils.general_utils import AttrDict\n",
    "import numpy as np\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from collections import OrderedDict \n",
    "\n",
    "\n",
    "from semiparametrictransfer.utils.construct_html import save_gif_list_direct\n",
    "from semiparametrictransfer.utils.construct_html import fill_template, save_html_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['DATA'] + '/spt_trainingdata' + '/sim/tabletop-texture'\n",
    "hp = AttrDict(img_sz=(48, 64),\n",
    "              sel_len=-1,\n",
    "              T=31)\n",
    "\n",
    "loader = FixLenVideoDataset(data_dir, hp).get_data_loader(32)\n",
    "\n",
    "num_batch = 100\n",
    "all_images = []\n",
    "all_object_qpos = []\n",
    "\n",
    "for i_batch, sample_batched in enumerate(loader):\n",
    "    images = np.asarray(sample_batched['demo_seq_images'])\n",
    "\n",
    "    images = (images + 1) / 2\n",
    "    images = np.transpose(images, [0, 1, 3, 4, 2])  # convert to channel-first\n",
    "    images = (images*255).astype(np.uint8)\n",
    "    actions = np.asarray(sample_batched['actions'])\n",
    "    states = np.asarray(sample_batched['states'])\n",
    "    \n",
    "    n_objects = 3\n",
    "    object_qpos = states[:, :, 9:15].reshape(states.shape[0], states.shape[1], n_objects, 2)\n",
    "    \n",
    "    if i_batch == num_batch - 1:\n",
    "        break\n",
    "        \n",
    "    all_images.append(images)\n",
    "    all_object_qpos.append(object_qpos)\n",
    "        \n",
    "#     plt.imshow(np.asarray(images[0, 0]))\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "all_images = np.concatenate(all_images, 0)\n",
    "all_object_qpos = np.concatenate(all_object_qpos, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/8978 [00:00<00:12, 695.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 8978 traj for train\n",
      "loading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8978/8978 [00:11<00:00, 774.77it/s]\n",
      "  2%|▏         | 8/499 [00:00<00:06, 71.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 499 traj for val\n",
      "loading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:05<00:00, 87.72it/s]\n",
      "  2%|▏         | 9/523 [00:00<00:06, 83.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 523 traj for test\n",
      "loading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [00:06<00:00, 85.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_traj(path):\n",
    "    with h5py.File(path, 'r') as F:\n",
    "        ex_index = 0\n",
    "        key = 'traj{}'.format(ex_index)\n",
    "\n",
    "        data_dict = {}\n",
    "        # Fetch data into a dict\n",
    "        for name in F[key].keys():\n",
    "            if name in ['states', 'actions']:\n",
    "                data_dict[name] = F[key + '/' + name].value.astype(np.float32)\n",
    "        states = data_dict['states']\n",
    "        n_objects = 3\n",
    "        data_dict['object_qpos'] = states[:, 9:15].reshape(states.shape[0], n_objects, 2)\n",
    "        data_dict['images'] = F[key + '/images'].value\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def _get_filenames(data_dir, phase):\n",
    "    assert 'hdf5' not in data_dir, \"hdf5 most not be containted in the data dir!\"\n",
    "    filenames = sorted(glob.glob(os.path.join(data_dir, os.path.join('hdf5', phase) + '/*')))\n",
    "    if not filenames:\n",
    "        raise RuntimeError('No filenames found in {}'.format(data_dir))\n",
    "    return filenames\n",
    "\n",
    "def load_all_data(orig_path):\n",
    "    phases = [\"train\", \"val\", \"test\"]\n",
    "    all_data_dict = OrderedDict()\n",
    "    for phase in phases:\n",
    "        filenames = _get_filenames(orig_path, phase)\n",
    "        print('found {} traj for {}'.format(len(filenames), phase))\n",
    "        print('loading files')\n",
    "        for path in tqdm(filenames):\n",
    "            single_filename = str.split(path, '/')[-1]\n",
    "            all_data_dict[single_filename] = read_traj(path)\n",
    "    return all_data_dict\n",
    "\n",
    "all_data_dict = load_all_data(os.environ['DATA'] + '/spt_trainingdata' + '/sim/tabletop-texture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_object_qpos = np.stack([all_data_dict[key]['object_qpos'] for key in all_data_dict.keys()])\n",
    "all_images = np.stack([all_data_dict[key]['images'] for key in all_data_dict.keys()]).squeeze()\n",
    "len(all_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'states', 'object_qpos', 'images'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_dict['traj_0to1.h5'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:13, 766.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_nearest_neighbors():\n",
    "    nearest_ind = {} \n",
    "    \n",
    "    obj_displacements = all_object_qpos[:, -1] - all_object_qpos[:, 0]\n",
    "    obj_displacements_mag = np.linalg.norm(obj_displacements, axis=-1)\n",
    "    largest_displacement_index = np.argmax(obj_displacements_mag, axis=1)\n",
    "    \n",
    "    num_vis_traj = 20\n",
    "    num_traj = all_object_qpos.shape[0]\n",
    "    vis_indices = [i for i in range(num_traj) if largest_displacement_index[i] > 0.01][:num_vis_traj]\n",
    "    \n",
    "    # get largest obj displacement per trajectory\n",
    "    largest_displacement = np.stack([obj_displacements[i, ind] for i, ind in enumerate(largest_displacement_index)])  \n",
    "    \n",
    "    for i, k in tqdm(enumerate(all_data_dict.keys())):\n",
    "        # compute the magnitude of differences between i-th displacement vector and all other displacements\n",
    "        diff_mag = np.linalg.norm(obj_displacements - largest_displacement[i][None, None], axis=-1)\n",
    "        \n",
    "        # take the minimum difference among all 3 objects:\n",
    "        diff_mag = np.min(diff_mag, axis=-1)\n",
    "        # get the batch indices of the lowest dist:\n",
    "        \n",
    "        numbest_k = 128\n",
    "        best_ind = np.argsort(diff_mag)[:numbest_k]\n",
    "        \n",
    "#         print('i {}: bestind {} largest disp {}'.format(i, best_ind[:10], largest_displacement[i]))\n",
    "                \n",
    "        nearest_ind[i] = best_ind\n",
    "        all_data_dict[k]['nearest_ind'] = best_ind\n",
    "    return nearest_ind, vis_indices\n",
    "nearest_ind, vis_indices = compute_nearest_neighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/99 [00:00<00:14,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 99 traj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:12<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# show only the nearest neighbors for the top 10\n",
    "show_nn_gifs = 5\n",
    "def save_gifs():\n",
    "    all_inds = []\n",
    "    \n",
    "    for k in vis_indices:\n",
    "        all_inds.append(k)\n",
    "        all_inds.extend(nearest_ind[k][:show_nn_gifs])\n",
    "            \n",
    "    all_inds = set(all_inds)\n",
    "    print('saving {} traj'.format(len(all_inds)))\n",
    "    gif_list = [(ind, all_images[ind]) for  ind in all_inds]\n",
    "    \n",
    "    folder = os.environ['DATA'] + '/spt_trainingdata' + '/sim/tabletop-texture/visuals'\n",
    "    name = 'sawyer'\n",
    "    html_paths = save_gif_list_direct(folder, name, gif_list)\n",
    "    return html_paths\n",
    "\n",
    "html_paths = save_gifs()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nearest_neighbor_gifs():\n",
    "    itemdict = {}\n",
    "    # show only the nearest neighbors for the top 10\n",
    "    for i in vis_indices:\n",
    "        nearest_ind_i = nearest_ind[i][:show_nn_gifs]\n",
    "        nearest_paths = [html_paths[ind] for ind in nearest_ind_i]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        itemdict['img{}'.format(i)] = [html_paths[i]] + nearest_paths\n",
    "            \n",
    "    html_page = fill_template(itemdict)\n",
    "    save_html_direct(os.environ['DATA'] + '/spt_trainingdata' + '/sim/tabletop-texture/visuals/index.html', html_page)\n",
    "    \n",
    "save_nearest_neighbor_gifs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nearest_neighbors():\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    all_data_dict_ = deepcopy(all_data_dict)\n",
    "    all_data_dict_noimages = {}\n",
    "    for key in all_data_dict.keys():\n",
    "        all_data_dict_[key].pop('images')  \n",
    "        all_data_dict_noimages[key] = all_data_dict_[key]\n",
    "    all_data_dict_noimages['traj_0to1.h5'].keys()\n",
    "        \n",
    "    import _pickle as pkl\n",
    "    pkl.dump(all_data_dict_noimages,\n",
    "             open(os.environ['DATA'] + '/spt_trainingdata' + '/sim/tabletop-texture/all_data_dict_noimages_trainvaltest.pkl', 'wb'))\n",
    "save_nearest_neighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
